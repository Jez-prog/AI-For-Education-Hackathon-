#!/usr/bin/env python
# -*- coding: utf-8 -*-
import csv
import copy
import argparse
import itertools
import mediapipe as mp

mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands

import numpy as np
mp_drawing = mp.solutions.drawing_utils
from collections import Counter
from collections import deque

import cv2 as cv
import numpy as np
import joblib


from utils import CvFpsCalc
from model import KeyPointClassifier
from model import PointHistoryClassifier
from model import KeyPointClassifier
from utils.cvfpscalc import CvFpsCalc
from model.keypoint_classifier.keypoint_classifier import landmarks_to_np_array






def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument("--device", type=int, default=0)
    parser.add_argument("--width", help='cap width', type=int, default=960)
    parser.add_argument("--height", help='cap height', type=int, default=540)

    parser.add_argument('--use_static_image_mode', action='store_true')
    parser.add_argument("--min_detection_confidence",
                        help='min_detection_confidence',
                        type=float,
                        default=0.7)
    parser.add_argument("--min_tracking_confidence",
                        help='min_tracking_confidence',
                        type=int,
                        default=0.5)

    args = parser.parse_args()

    return args


def main():
    gesture_classifier = KeyPointClassifier()
    # Argument parsing #################################################################
    fps_calculator = CvFpsCalc(buffer_len=10)
    args = get_args()

    cap_device = args.device
    cap_width = args.width
    cap_height = args.height

    use_static_image_mode = args.use_static_image_mode
    min_detection_confidence = args.min_detection_confidence
    min_tracking_confidence = args.min_tracking_confidence

    use_brect = True

    # Camera preparation ###############################################################
    cap = cv.VideoCapture(cap_device)
    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)
    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)

    # Model load #############################################################
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(
        static_image_mode=use_static_image_mode,
        max_num_hands=2,
        min_detection_confidence=min_detection_confidence,
        min_tracking_confidence=min_tracking_confidence,
    )

    keypoint_classifier = KeyPointClassifier()

    point_history_classifier = PointHistoryClassifier()

    # Read labels ###########################################################
    with open('model/keypoint_classifier/keypoint_classifier_label.csv',
              encoding='utf-8-sig') as f:
        keypoint_classifier_labels = csv.reader(f)
        keypoint_classifier_labels = [
            row[0] for row in keypoint_classifier_labels
        ]
    with open(
            'model/point_history_classifier/point_history_classifier_label.csv',
            encoding='utf-8-sig') as f:
        point_history_classifier_labels = csv.reader(f)
        point_history_classifier_labels = [
            row[0] for row in point_history_classifier_labels
        ]

    # FPS Measurement ########################################################
    cvFpsCalc = CvFpsCalc(buffer_len=10)

    # Coordinate history #################################################################
    history_length = 16
    point_history = deque(maxlen=history_length)

    # Finger gesture history ################################################
    finger_gesture_history = deque(maxlen=history_length)

    #  ########################################################################
    mode = 0

    while True:
        fps = cvFpsCalc.get()

        # Process Key (ESC: end) #################################################
        key = cv.waitKey(10)
        if key == 27:  # ESC
            break

            # Calculate FPS
            fps = fps_calculator.get()
            cv.putText(image, f'FPS: {fps}', (10, 30),
                       cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2, cv.LINE_AA)

            # Show image
            cv.imshow('Hand Gesture', image)

        number, mode = select_mode(key, mode)

        # Camera capture #####################################################
        ret, image = cap.read()
        if not ret:
            break
        image = cv.flip(image, 1)  # Mirror display
        debug_image = copy.deepcopy(image)

        # Detection implementation #############################################################
        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)

        image.flags.writeable = False
        results = hands.process(image)
        image.flags.writeable = True

        if results.multi_hand_landmarks:
            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):
                # Draw the hand landmarks
                mp_drawing.draw_landmarks(
                    image,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),
                    mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)
                )

                # Get handedness ("Left" or "Right")
                hand_label = handedness.classification[0].label

                # Get wrist position and map to image coords
                wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
                x = int(wrist.x * image.shape[1])
                y = int(wrist.y * image.shape[0]) - 30  # Slightly above the hand

                # Set color for label
                if hand_label == "Left":
                    color = (255, 0, 0)  # üîµ Blue for Left
                else:
                    color = (0, 255, 0)  # üü¢ Green for Right

                # Draw the label on the image
                cv.putText(
                    image,
                    f"{hand_label}",
                    (x, y),
                    cv.FONT_HERSHEY_SIMPLEX,
                    1,
                    color,
                    3,
                    cv.LINE_AA
                )

                # Get handedness label ("Left" or "Right")
                hand_label = handedness.classification[0].label

                # Get wrist position for text placement
                wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
                text_x = int(wrist.x * image.shape[1])
                text_y = int(wrist.y * image.shape[0]) - 50  # Higher above the hand

                # Set colors and styles
                if hand_label == "Left":
                    color = (255, 100, 100)  # Light red
                    bg_color = (50, 50, 200)  # Dark blue background
                else:
                    color = (100, 255, 100)  # Light green
                    bg_color = (200, 50, 50)  # Dark red background

                # Text settings
                font = cv.FONT_HERSHEY_SIMPLEX
                font_scale = 1.5  # Bigger text
                thickness = 3
                text_size = cv.getTextSize(hand_label, font, font_scale, thickness)[0]

                # Draw background rectangle
                padding = 20
                cv.rectangle(image,
                             (text_x - padding // 2, text_y - text_size[1] - padding // 2),
                             (text_x + text_size[0] + padding // 2, text_y + padding // 2),
                             bg_color, -1)

                # Draw outline text (for better visibility)
                cv.putText(image, hand_label, (text_x, text_y), font,
                           font_scale, (0, 0, 0), thickness + 2, cv.LINE_AA)

                # Draw main text
                cv.putText(image, hand_label, (text_x, text_y), font,
                           font_scale, color, thickness, cv.LINE_AA)

        #  ####################################################################
        if results.multi_hand_landmarks is not None:
            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,
                                                  results.multi_handedness):
                # Bounding box calculation
                brect = calc_bounding_rect(debug_image, hand_landmarks)
                # Landmark calculation
                landmark_list = calc_landmark_list(debug_image, hand_landmarks)

                # Conversion to relative coordinates / normalized coordinates
                pre_processed_landmark_list = pre_process_landmark(
                    landmark_list)
                pre_processed_point_history_list = pre_process_point_history(
                    debug_image, point_history)
                # Write to the dataset file
                logging_csv(number, mode, pre_processed_landmark_list,
                            pre_processed_point_history_list)

                # Hand sign classification
                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)
                if hand_sign_id == 2:  # Point gesture
                    point_history.append(landmark_list[8])
                else:
                    point_history.append([0, 0])

                # Finger gesture classification
                finger_gesture_id = 0
                point_history_len = len(pre_processed_point_history_list)
                if point_history_len == (history_length * 2):
                    finger_gesture_id = point_history_classifier(
                        pre_processed_point_history_list)

                # Calculates the gesture IDs in the latest detection
                finger_gesture_history.append(finger_gesture_id)
                most_common_fg_id = Counter(
                    finger_gesture_history).most_common()

                # Drawing part
                debug_image = draw_bounding_rect(use_brect, debug_image, brect)
                debug_image = draw_landmarks(debug_image, landmark_list)  # <-- Now uncommented
                debug_image = draw_info_text(
                    debug_image,
                    brect,
                    handedness,
                    keypoint_classifier_labels[hand_sign_id],
                    point_history_classifier_labels[most_common_fg_id[0][0]],
                )
        else:
            point_history.append([0, 0])

        debug_image = draw_point_history(debug_image, point_history)
        debug_image = draw_info(debug_image, fps, mode, number)

        # Screen reflection #############################################################
        cv.imshow('Hand Gesture Recognition', debug_image)

    cap.release()
    cv.destroyAllWindows()


def select_mode(key, mode):
    number = -1
    if 48 <= key <= 57:  # 0 ~ 9
        number = key - 48
    if key == 110:  # n
        mode = 0
    if key == 107:  # k
        mode = 1
    if key == 104:  # h
        mode = 2
    return number, mode


def calc_bounding_rect(image, landmarks):
    image_width, image_height = image.shape[1], image.shape[0]

    landmark_array = np.empty((0, 2), int)

    for _, landmark in enumerate(landmarks.landmark):
        landmark_x = min(int(landmark.x * image_width), image_width - 1)
        landmark_y = min(int(landmark.y * image_height), image_height - 1)

        landmark_point = [np.array((landmark_x, landmark_y))]

        landmark_array = np.append(landmark_array, landmark_point, axis=0)

    x, y, w, h = cv.boundingRect(landmark_array)

    return [x, y, x + w, y + h]


def calc_landmark_list(image, landmarks):
    image_width, image_height = image.shape[1], image.shape[0]

    landmark_point = []

    # Keypoint
    for _, landmark in enumerate(landmarks.landmark):
        landmark_x = min(int(landmark.x * image_width), image_width - 1)
        landmark_y = min(int(landmark.y * image_height), image_height - 1)
        # landmark_z = landmark.z

        landmark_point.append([landmark_x, landmark_y])

    return landmark_point


def pre_process_landmark(landmark_list):
    temp_landmark_list = copy.deepcopy(landmark_list)

    # Convert to relative coordinates
    base_x, base_y = 0, 0
    for index, landmark_point in enumerate(temp_landmark_list):
        if index == 0:
            base_x, base_y = landmark_point[0], landmark_point[1]

        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x
        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y

    # Convert to a one-dimensional list
    temp_landmark_list = list(
        itertools.chain.from_iterable(temp_landmark_list))

    # Normalization
    max_value = max(list(map(abs, temp_landmark_list)))

    def normalize_(n):
        return n / max_value

    temp_landmark_list = list(map(normalize_, temp_landmark_list))

    return temp_landmark_list


def pre_process_point_history(image, point_history):
    image_width, image_height = image.shape[1], image.shape[0]

    temp_point_history = copy.deepcopy(point_history)

    # Convert to relative coordinates
    base_x, base_y = 0, 0
    for index, point in enumerate(temp_point_history):
        if index == 0:
            base_x, base_y = point[0], point[1]

        temp_point_history[index][0] = (temp_point_history[index][0] -
                                        base_x) / image_width
        temp_point_history[index][1] = (temp_point_history[index][1] -
                                        base_y) / image_height

    # Convert to a one-dimensional list
    temp_point_history = list(
        itertools.chain.from_iterable(temp_point_history))

    return temp_point_history


def logging_csv(number, mode, landmark_list, point_history_list):
    if mode == 0:
        pass
    if mode == 1 and (0 <= number <= 9):
        csv_path = 'model/keypoint_classifier/keypoint.csv'
        with open(csv_path, 'a', newline="") as f:
            writer = csv.writer(f)
            writer.writerow([number, *landmark_list])
    if mode == 2 and (0 <= number <= 9):
        csv_path = 'model/point_history_classifier/point_history.csv'
        with open(csv_path, 'a', newline="") as f:
            writer = csv.writer(f)
            writer.writerow([number, *point_history_list])
    return


def draw_landmarks(image, landmark_point):
    if len(landmark_point) > 0:
        # Custom colors
        palm_color = (255, 178, 102)  # Light orange
        thumb_color = (255, 102, 102)  # Coral
        index_color = (102, 255, 178)  # Mint
        middle_color = (102, 178, 255)  # Sky blue
        ring_color = (178, 102, 255)  # Lavender
        pinky_color = (255, 102, 178)  # Pink
        joint_color = (255, 255, 255)  # White
        tip_color = (255, 255, 0)  # Yellow

        # Palm connections (more organic shape)
        palm_connections = [
            (0, 1), (1, 2), (2, 5), (5, 9), (9, 13), (13, 17), (17, 0),
            (0, 5), (5, 17)
        ]

        for connection in palm_connections:
            cv.line(image, tuple(landmark_point[connection[0]]), tuple(landmark_point[connection[1]]),
                    palm_color, 4)

        # Finger connections with different colors
        finger_connections = [
            (thumb_color, [(2, 3), (3, 4)]),
            (index_color, [(5, 6), (6, 7), (7, 8)]),
            (middle_color, [(9, 10), (10, 11), (11, 12)]),
            (ring_color, [(13, 14), (14, 15), (15, 16)]),
            (pinky_color, [(17, 18), (18, 19), (19, 20)])
        ]

        for color, connections in finger_connections:
            for connection in connections:
                cv.line(image, tuple(landmark_point[connection[0]]), tuple(landmark_point[connection[1]]),
                        color, 3)

        # Draw joints with different styles
        for index, landmark in enumerate(landmark_point):
            radius = 5
            color = joint_color
            thickness = -1  # Filled

            if index in [4, 8, 12, 16, 20]:  # Finger tips
                radius = 8
                color = tip_color
                # Draw glow effect
                cv.circle(image, (landmark[0], landmark[1]), radius + 2,
                          (color[0] // 2, color[1] // 2, color[2] // 2), -1)

            cv.circle(image, (landmark[0], landmark[1]), radius, color, thickness)

            # Add subtle outline
            cv.circle(image, (landmark[0], landmark[1]), radius + 1,
                      (color[0] // 3, color[1] // 3, color[2] // 3), 1)

        # Add subtle glow to the entire hand
        overlay = image.copy()
        alpha = 0.3
        for connection in palm_connections + [c for _, cs in finger_connections for c in cs]:
            cv.line(overlay, tuple(landmark_point[connection[0]]), tuple(landmark_point[connection[1]]),
                    (255, 255, 255), 8)
        image = cv.addWeighted(overlay, alpha, image, 1 - alpha, 0)

    return image

    # Key Points
    for index, landmark in enumerate(landmark_point):
        if index == 0:  # ÊâãÈ¶ñ1
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 1:  # ÊâãÈ¶ñ2
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 2:  # Ë¶™ÊåáÔºö‰ªò„ÅëÊ†π
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 3:  # Ë¶™ÊåáÔºöÁ¨¨1Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 4:  # Ë¶™ÊåáÔºöÊåáÂÖà
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 5:  # ‰∫∫Â∑ÆÊåáÔºö‰ªò„ÅëÊ†π
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 6:  # ‰∫∫Â∑ÆÊåáÔºöÁ¨¨2Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 7:  # ‰∫∫Â∑ÆÊåáÔºöÁ¨¨1Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 8:  # ‰∫∫Â∑ÆÊåáÔºöÊåáÂÖà
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 9:  # ‰∏≠ÊåáÔºö‰ªò„ÅëÊ†π
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 10:  # ‰∏≠ÊåáÔºöÁ¨¨2Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 11:  # ‰∏≠ÊåáÔºöÁ¨¨1Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 12:  # ‰∏≠ÊåáÔºöÊåáÂÖà
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 13:  # Ëñ¨ÊåáÔºö‰ªò„ÅëÊ†π
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 14:  # Ëñ¨ÊåáÔºöÁ¨¨2Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 15:  # Ëñ¨ÊåáÔºöÁ¨¨1Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 16:  # Ëñ¨ÊåáÔºöÊåáÂÖà
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 17:  # Â∞èÊåáÔºö‰ªò„ÅëÊ†π
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 18:  # Â∞èÊåáÔºöÁ¨¨2Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 19:  # Â∞èÊåáÔºöÁ¨¨1Èñ¢ÁØÄ
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 20:  # Â∞èÊåáÔºöÊåáÂÖà
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)

    return image


def draw_bounding_rect(use_brect, image, brect):
    if use_brect:
        # Outer rectangle
       # cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),
       #              (0, 0, 0), 1)
        pass
    return image


def draw_info_text(image, brect, handedness, hand_sign_text,
                   finger_gesture_text):
   # cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),
     #            (0, 0, 0), -1)

    info_text = handedness.classification[0].label[0:]
    if hand_sign_text != "":
        info_text = info_text + ':' + hand_sign_text
    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),
               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)

    if finger_gesture_text != "":
        cv.putText(image, "Finger Gesture:" + finger_gesture_text, (10, 60),
                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv.LINE_AA)
        cv.putText(image, "Finger Gesture:" + finger_gesture_text, (10, 60),
                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,
                   cv.LINE_AA)

    return image


def draw_point_history(image, point_history):
    for index, point in enumerate(point_history):
        if point[0] != 0 and point[1] != 0:
            cv.circle(image, (point[0], point[1]), 1 + int(index / 2),
                      (152, 251, 152), 2)

    return image


def draw_info(image, fps, mode, number):
    cv.putText(image, "FPS:" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,
               1.0, (0, 0, 0), 4, cv.LINE_AA)
    cv.putText(image, "FPS:" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,
               1.0, (255, 255, 255), 2, cv.LINE_AA)

    mode_string = ['Logging Key Point', 'Logging Point History']
    if 1 <= mode <= 2:
        cv.putText(image, "MODE:" + mode_string[mode - 1], (10, 90),
                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,
                   cv.LINE_AA)
        if 0 <= number <= 9:
            cv.putText(image, "NUM:" + str(number), (10, 110),
                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,
                       cv.LINE_AA)
    return image


if __name__ == '__main__':
    main()
